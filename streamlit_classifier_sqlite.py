"""
================================================
Streamlit ã‚¹ã‚¿ã‚¸ã‚ªåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  - æœ€é©åŒ–ç‰ˆ
å†å®Ÿè¡Œå•é¡Œã‚’è§£æ±ºã—ã€å‡¦ç†ã®å®‰å®šæ€§ã‚’å‘ä¸Š
================================================
ãƒ•ã‚¡ã‚¤ãƒ«å: streamlit_app_optimized.py
å®Ÿè¡Œ: streamlit run streamlit_app_optimized.py
================================================
"""

import os
import json
import sqlite3
from datetime import datetime
from typing import List, Dict, Any
import streamlit as st
import google.generativeai as genai
from PIL import Image
import io
from dotenv import load_dotenv
import hashlib
import time

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ã‚¹ã‚¿ã‚¸ã‚ªåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ", page_icon="ğŸ“¸", layout="wide")

# ================================================
# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆå¤‰æ›´ãªã—ï¼‰
# ================================================
st.markdown(
    """
<style>
    .tag-badge {
        background-color: #e3f2fd;
        color: #1976d2;
        padding: 6px 12px;
        border-radius: 16px;
        font-size: 14px;
        display: inline-block;
        margin: 2px;
    }
    .category-tag {
        background-color: #fff3e0;
        color: #f57c00;
        font-weight: bold;
    }
    .impression-tag {
        background-color: #f3e5f5;
        color: #7b1fa2;
    }
    .object-tag {
        background-color: #e8f5e9;
        color: #388e3c;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã¨ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³
# ================================================
@st.cache_resource
def init_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
    db_path = "studio_tags.db"
    conn = sqlite3.connect(db_path, check_same_thread=False)

    # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS tag_configs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            classification_hierarchy TEXT,
            impression_tags TEXT,
            object_tags TEXT,
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        )
    """
    )

    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS analysis_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            analysis_id TEXT UNIQUE,
            folder_name TEXT,
            broad_category TEXT,
            specific_item TEXT,
            impression_tags TEXT,
            object_tags TEXT,
            reason TEXT,
            purpose TEXT,
            features TEXT,
            image_count INTEGER,
            analyzed_at TIMESTAMP
        )
    """
    )

    conn.commit()
    return conn


@st.cache_resource
def init_gemini():
    """Gemini APIã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
    API_KEY = os.environ.get("GEMINI_API_KEY")
    if not API_KEY:
        return None

    genai.configure(api_key=API_KEY)
    return genai.GenerativeModel("gemini-2.0-flash")


# ================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰
# ================================================
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–"""

    # åˆ†æçŠ¶æ…‹ã®ç®¡ç†
    if "analysis_in_progress" not in st.session_state:
        st.session_state.analysis_in_progress = False

    if "current_analysis_id" not in st.session_state:
        st.session_state.current_analysis_id = None

    if "analysis_results" not in st.session_state:
        st.session_state.analysis_results = []

    # ã‚¿ã‚°è¨­å®š
    if "classification_hierarchy" not in st.session_state:
        st.session_state.classification_hierarchy = {
            "ãƒã‚¦ã‚¹ã‚¹ã‚¿ã‚¸ã‚ª": ["å’Œé¢¨", "æ´‹é¢¨", "ä¸€è»’å®¶", "ãƒãƒ³ã‚·ãƒ§ãƒ³", "ã‚¢ãƒ‘ãƒ¼ãƒˆ"],
            "ã‚ªãƒ•ã‚£ã‚¹": ["åŸ·å‹™å®¤", "ä¼šè­°å®¤", "ãƒ­ãƒ“ãƒ¼"],
            "é£²é£Ÿåº—": ["ã‚«ãƒ•ã‚§", "ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "BAR", "å±…é…’å±‹"],
            "ãã®ä»–": ["é§è»Šå ´", "å±‹ä¸Š", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚¹ãƒšãƒ¼ã‚¹"],
        }

    if "impression_tags" not in st.session_state:
        st.session_state.impression_tags = {
            "é›°å›²æ°—": [
                {"label": "ãƒ¢ãƒ€ãƒ³", "slug": "modern"},
                {"label": "ãƒ¬ãƒˆãƒ­", "slug": "retro"},
                {"label": "ãƒŠãƒãƒ¥ãƒ©ãƒ«", "slug": "natural"},
            ]
        }

    if "object_tags" not in st.session_state:
        st.session_state.object_tags = {
            "å®¶å…·": [
                {"label": "ã‚½ãƒ•ã‚¡", "slug": "sofa"},
                {"label": "ãƒ†ãƒ¼ãƒ–ãƒ«", "slug": "table"},
            ]
        }


# ================================================
# åˆ†æå‡¦ç†ï¼ˆéåŒæœŸå‡¦ç†å¯¾å¿œï¼‰
# ================================================
def generate_analysis_id(folder_name: str) -> str:
    """ä¸€æ„ã®åˆ†æIDã‚’ç”Ÿæˆ"""
    timestamp = datetime.now().isoformat()
    unique_string = f"{folder_name}_{timestamp}"
    return hashlib.md5(unique_string.encode()).hexdigest()[:12]


def perform_analysis(
    images: List[Image.Image], folder_name: str, options: Dict
) -> Dict:
    """ç”»åƒåˆ†æã‚’å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰"""

    model = init_gemini()
    if not model:
        return {"error": "Gemini APIãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"}

    # åˆ†æIDã‚’ç”Ÿæˆ
    analysis_id = generate_analysis_id(folder_name)
    st.session_state.current_analysis_id = analysis_id

    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ä¸å‹•ç”£ãƒ»æ’®å½±ã‚¹ã‚¿ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
{len(images)}æšã®å†™çœŸã‚’ç·åˆçš„ã«åˆ†æã—ã€ç‰©ä»¶ã‚’åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

åˆ†é¡éšå±¤:
{json.dumps(st.session_state.classification_hierarchy, ensure_ascii=False)}

å°è±¡ã‚¿ã‚°:
{json.dumps(st.session_state.impression_tags, ensure_ascii=False)}

ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚°:
{json.dumps(st.session_state.object_tags, ensure_ascii=False)}

JSONå½¢å¼ã§å‡ºåŠ›:
{{
    "å¤§åˆ†é¡": "é¸æŠ",
    "å°é …ç›®": "é¸æŠ",
    "å°è±¡ã‚¿ã‚°": ["slug1", "slug2"],
    "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚°": ["slug1", "slug2"],
    "åˆ¤å®šç†ç”±": "50æ–‡å­—ä»¥å†…",
    "æ’®å½±ç”¨é€”": "ç”¨é€”ä¾‹",
    "ç‰¹å¾´": "ç‰¹å¾´çš„ãªè¦ç´ "
}}
"""

        # Gemini APIã‚³ãƒ¼ãƒ«ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰
        response = model.generate_content(
            [prompt] + images,
            generation_config=genai.GenerationConfig(
                response_mime_type="application/json",
                temperature=0.7,
                max_output_tokens=1024,
            ),
        )

        result = json.loads(response.text)
        result["analysis_id"] = analysis_id
        result["ãƒ•ã‚©ãƒ«ãƒ€å"] = folder_name
        result["ç”»åƒæšæ•°"] = len(images)
        result["åˆ†ææ—¥æ™‚"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        return result

    except Exception as e:
        return {
            "error": str(e),
            "analysis_id": analysis_id,
            "ãƒ•ã‚©ãƒ«ãƒ€å": folder_name,
            "ç”»åƒæšæ•°": len(images),
        }


def save_analysis_result(result: Dict, conn: sqlite3.Connection):
    """åˆ†æçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    existing = conn.execute(
        "SELECT analysis_id FROM analysis_history WHERE analysis_id = ?",
        (result.get("analysis_id", ""),),
    ).fetchone()

    if not existing:
        conn.execute(
            """
            INSERT INTO analysis_history
            (analysis_id, folder_name, broad_category, specific_item,
             impression_tags, object_tags, reason, purpose, features,
             image_count, analyzed_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                result.get("analysis_id", ""),
                result.get("ãƒ•ã‚©ãƒ«ãƒ€å", ""),
                result.get("å¤§åˆ†é¡", ""),
                result.get("å°é …ç›®", ""),
                json.dumps(result.get("å°è±¡ã‚¿ã‚°", []), ensure_ascii=False),
                json.dumps(result.get("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚°", []), ensure_ascii=False),
                result.get("åˆ¤å®šç†ç”±", ""),
                result.get("æ’®å½±ç”¨é€”", ""),
                result.get("ç‰¹å¾´", ""),
                result.get("ç”»åƒæšæ•°", 0),
                datetime.now(),
            ),
        )
        conn.commit()


# ================================================
# UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰
# ================================================
def render_analysis_tab():
    """ç”»åƒåˆ†æã‚¿ãƒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰"""

    st.subheader("ğŸ“¤ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨åˆ†æ")

    # åˆ†æä¸­ã®å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
    if st.session_state.analysis_in_progress:
        st.warning("â³ åˆ†æå‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")

    col1, col2 = st.columns([2, 1])

    with col1:
        uploaded_files = st.file_uploader(
            "ç”»åƒã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰",
            type=["jpg", "jpeg", "png"],
            accept_multiple_files=True,
            key="file_uploader",
        )

        if uploaded_files:
            st.success(f"ğŸ“ {len(uploaded_files)}æšã®ç”»åƒã‚’é¸æŠä¸­")

            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆè»½é‡åŒ–ï¼‰
            with st.expander("ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                preview_cols = st.columns(4)
                for i, file in enumerate(uploaded_files[:4]):
                    preview_cols[i].image(file, use_container_width=True)

    with col2:
        folder_name = st.text_input(
            "ç‰©ä»¶å/ãƒ•ã‚©ãƒ«ãƒ€å",
            placeholder="ä¾‹: æ¸‹è°·_ã‚¹ã‚¿ã‚¸ã‚ªA",
            key="folder_name_input",
        )

        # åˆ†æãƒœã‚¿ãƒ³ï¼ˆäºŒé‡é€ä¿¡é˜²æ­¢ï¼‰
        analyze_button = st.button(
            "ğŸš€ åˆ†æé–‹å§‹",
            type="primary",
            use_container_width=True,
            disabled=st.session_state.analysis_in_progress,
            key="analyze_button",
        )

        if analyze_button and uploaded_files and folder_name:
            # åˆ†æé–‹å§‹
            st.session_state.analysis_in_progress = True

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_bar = st.progress(0, text="ç”»åƒã‚’æº–å‚™ä¸­...")

            try:
                # ç”»åƒæº–å‚™
                images = []
                for i, file in enumerate(uploaded_files):
                    progress_bar.progress(
                        (i + 1) / (len(uploaded_files) + 1),
                        text=f"ç”»åƒã‚’å‡¦ç†ä¸­... ({i + 1}/{len(uploaded_files)})",
                    )

                    image = Image.open(file)
                    if image.mode != "RGB":
                        image = image.convert("RGB")
                    # ã‚µã‚¤ã‚ºèª¿æ•´
                    image.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                    images.append(image)

                # åˆ†æå®Ÿè¡Œ
                progress_bar.progress(0.9, text="AIãŒåˆ†æä¸­...")

                result = perform_analysis(images, folder_name, {"use_all": True})

                if "error" not in result:
                    # æˆåŠŸ
                    st.session_state.analysis_results.append(result)

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    conn = init_database()
                    save_analysis_result(result, conn)

                    progress_bar.progress(1.0, text="å®Œäº†ï¼")
                    st.success("âœ… åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.balloons()

                    # çµæœã‚’è¡¨ç¤º
                    with st.expander("ğŸ“Š åˆ†æçµæœ", expanded=True):
                        col_r1, col_r2 = st.columns(2)
                        with col_r1:
                            st.metric("å¤§åˆ†é¡", result.get("å¤§åˆ†é¡", "ä¸æ˜"))
                            st.metric("å°é …ç›®", result.get("å°é …ç›®", "ä¸æ˜"))
                        with col_r2:
                            st.metric("æ’®å½±ç”¨é€”", result.get("æ’®å½±ç”¨é€”", "ä¸æ˜"))
                            st.info(result.get("åˆ¤å®šç†ç”±", ""))
                else:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")

            except Exception as e:
                st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

            finally:
                # åˆ†æå®Œäº†
                st.session_state.analysis_in_progress = False
                time.sleep(1)
                st.rerun()


def render_history_tab():
    """å±¥æ­´ã‚¿ãƒ–ï¼ˆæ”¹å–„ç‰ˆï¼‰"""

    st.subheader("ğŸ“Š åˆ†æå±¥æ­´")

    conn = init_database()

    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
    page_size = 10
    total_count = conn.execute("SELECT COUNT(*) FROM analysis_history").fetchone()[0]

    if total_count > 0:
        page = st.number_input(
            "ãƒšãƒ¼ã‚¸",
            min_value=1,
            max_value=(total_count + page_size - 1) // page_size,
            value=1,
        )

        offset = (page - 1) * page_size

        history = conn.execute(
            """
            SELECT * FROM analysis_history
            ORDER BY analyzed_at DESC
            LIMIT ? OFFSET ?
        """,
            (page_size, offset),
        ).fetchall()

        for record in history:
            with st.expander(f"ğŸ“ {record[2]} - {record[3]} ({record[9][:16]})"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**å¤§åˆ†é¡**: {record[3]}")
                    st.write(f"**å°é …ç›®**: {record[4]}")
                    st.write(f"**ç”»åƒæ•°**: {record[8]}æš")
                with col2:
                    st.write(f"**åˆ¤å®šç†ç”±**: {record[6]}")
                    st.write(f"**æ’®å½±ç”¨é€”**: {record[7]}")
    else:
        st.info("ã¾ã åˆ†æå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")


# ================================================
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ================================================
def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    # åˆæœŸåŒ–
    init_session_state()

    # APIãƒã‚§ãƒƒã‚¯
    model = init_gemini()
    if not model:
        st.error("âŒ GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.stop()

    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ“¸ ã‚¹ã‚¿ã‚¸ã‚ªç‰©ä»¶åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰")

    # ã‚¿ãƒ–æ§‹æˆ
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ç”»åƒåˆ†æ", "ğŸ“Š åˆ†æå±¥æ­´", "âš™ï¸ è¨­å®š"])

    with tab1:
        render_analysis_tab()

    with tab2:
        render_history_tab()

    with tab3:
        st.info("è¨­å®šç®¡ç†æ©Ÿèƒ½ã¯åˆ¥é€”å®Ÿè£…")


if __name__ == "__main__":
    main()
